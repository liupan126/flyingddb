---
typora-copy-images-to: FDD集群管理开发详细设计image
---

# FDD 集群管理开发详细设计

飞象分布式数据库（ Flying Distributed Database，本文统一简称：FDD）是一个基于开源数据库Postgres-XL开发的分布式并行关系型数据库系统。

FDD提供以下功能特性：

- 完全的ACID支持

  支持分布式集群级别的ACID特性

- 可横向扩展的关系型数据库（RDBMS）

  支持OLAP应用，采用MPP架构模式，支持OLTP应用，读写性能可扩展，可被用作分布式Key-Value存储

- 标准SQL支持

  支持丰富的SQL语句类型，比如：关联子查询

- 应用程序接口

  支持所有支持PostgresSQL类型的驱动，包括： JDBC、 ODBC、 OLE DB、Python、Ruby、 perl DBI等

但是，现在的FDD集群在易用性、可维护性和可靠性上存在如下问题：

1.  集群布署繁琐

   在布署时，需要在每个主机上进行编译、需要在每台机器上创建运行目录、修改每台机器的环境变量、把用到的通信端口添加到防火墙白名单、需要设置ssh免密码登录等等；

2.  集群运维不易

   缺少统一的集群组件管理、用户管理、配置管理等能力，都只能够在主机上按步骤手动修改或查询。

3.  高可靠性欠缺

   缺少故障处理和告警模块，无法自动对集群各组件进行故障监控、告警和恢复等功能，都需要人工介入。

4. 可扩展性不足

   集群扩容需要重分布，无法支持在线扩容，也没法自动适应双活、两地三中心、多地多中心等场景。

为了解决FDD集群在易用性、可维护性和可靠性上存在的问题，故在原有基础上新增FDD集群管理（Cluster Manager，本文统一简称：CM）运维系统，用于提供易用、稳健、高可靠的集群管理能力，支持集群的一键式安装部署、监控、告警、集群组件管理、用户管理、配置管理、健康检查、问题定位、升级和补丁等功能。

本文将主要描述FDD集群管理系统的详细设计方案，着重从代码层面来介绍整体架构设计、各组成模块的设计以及各种场景下的处理流程等。

## 一、框架设计

本章节主要介绍飞象分布式数据库系统（ Flying Distributed Database System，本文统一简称：FDDS）的整体逻辑架构、系统内部依赖关系和CM的实现结构等内容，从整体上来说明FDDS的实现框架。

### 1.1、逻辑架构

飞象分布式数据库系统（FDDS）由飞象分布式数据库（FDD）和集群管理系统（CM）组成，其整体逻辑架构如下图所示：

![1543457761143](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543457761143.png)

<center>图1、FDDS逻辑架构图<center\>

各组件提供的功能如下：

- FDD：基于MPP架构的分布式数据库，可方便进行水平扩展的数据库解决方案。
- CM：集群管理系统，负责在FDD运行过程中提供运维服务，为其提供易用、稳健、高可靠的集群管理功能。

在新增CM系统后，新的FDDS的结构图和各组件之间的依赖关系，如下图所示：

![1543474564272](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543474564272.png)

<center>图2、FDDS结构图<center\>

上图中各模块的含义如下表所示：

<center>表一、FDDS各模块含义表<center\>

| 模块名称          | 描述                                                         |
| ----------------- | ------------------------------------------------------------ |
| CM（Center）      | 它是整个CM的决策者，有主备之分，正常情况下，只由主Center提供FDDS集群管理服务，它会根据Agent上报上来的各功能单元状态信息来决定是否需要状态变更；而只有主Center故障时，备Center才会自动升为主，用于接管FDDS集群管理服务 |
| CM（Agent）       | 每个集群主机上面部署的实例代理线程，负责接收Center下发的命令和上报每个服务器上的Coordinator、Datanode、GTM的状态给Center。 |
| FDD（GTM）        | 全局事务管理器（GTM），它负责生成和维护全局事务ID、事务快照、时间戳等需要全局唯一的信息。GTM分为主GTM和备GTM。正常情况下，只由主GTM提供全局事务管理服务。当主GTM发生故障的情况下，备GTM会主动升为主GTM提供服务。 |
| FDD（GTM_Proxy）  | 它用于代理Coordinator和Datanode对GTM的访问，起到减轻GTM负载的作用；并且助完成GTM的故障切换。 |
| FDD（Coordinate） | 协调器（Coordinator），负责提供外部应用接口、优化全局执行计划、向Datanode分发执行计划，以及汇总、处理执行结果。 |
| FDD（DataNode）   | 数据节点（DataNode），它是实际存取数据的节点，接收Coordinator的请求并执行SQL语句，用于存取或查询数据，节点之间也会互相通信。可以根据可靠性级别，配置相应的若干个备DataNode，避免数据丢失时，及时进行数据恢复 |

### 1.2、CM结构设计

从前面的图2和表一可以看出，CM由Center和Agent组成，这两个进程相互协调和配合，用于管理和监控FDDS分布式系统中各个功能单元和物理资源的运行情况，确保整个FDDS系统的稳定运行。这两个进程的功能分别为：

Center为集群管理进程：它主要负责FDDS分布式集群的布署、初始化、启动、停止；负责所有集群节点的参数设置；负责发起容灾切换；也包括集群的后续扩缩容等功能 。

Agent为集群各主机的代理进程：该进程布署在组成FDDS集群的主机上，每个主机一个；Center通过Agent进程实现对FDDS集群的管理，是对该主机中各节点（可能一个主机中同时部署了gtm_proxy、coordinate、DataNode等）的具体管理者；同时还负责灾备过程中集群可靠性的实现，负责所在主机中各节点状态采集、状态上报、接收指令计划和下发执行指令；另外还负责配合解决脑裂、容灾切换等功能。

根据《FDD 集群管理开发概要设计.docx》文档描述可知，本设计方案选取ETCD来存储CM的元数据，并且来实现Center的选主；而FDD和CM相互配合，共同组成了FDDS分布式数据库集群系统，他们两者之间的依赖关系和内部的实现层次，如下图所示：

![1543481219658](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543481219658.png)

<center>图3、FDDS内部关系图<center\>  
### 1.3、CM模块设计

Center和Agent两个进程是组成CM的关键，依据他们的职责和功能，并且兼顾后面的代码和组件复用，所以把整个CM系统，在代码开发层面拆解为12个独立的模块（注：因为Center和Agent两个进程支持动态库和静态库链接两种编译方式，所以有些模块就需要编译为静态库或动态库），如下表所示：

<center>表二、组成CM的各独立模块<center\>

| 名称                          | 类型       | 描述                                                         |
| :---------------------------- | ---------- | ------------------------------------------------------------ |
| Center进程                    | 可执行程序 | 负责和K-V存储进行数据交互，接收和处理管理命令，并且制定执行计划，下发给对应Agent，收集和处理各Agent返回的状态信息来决定是否需要状态变更 |
| Agent进程                     | 可执行程序 | 负责接收和处理Center下发的命令、上报所在主机上相关节点状态给Center等操作 |
| 日志（Log）模块               | 静(动)态库 | 负责日志打印，具有多种日志打印模式                           |
| 公共组件（Common）模块        | 静(动)态库 | 提供统一的错误码、公共宏定义、公共的常用函数、md5算法类、进程单例启动类、解析启动参数类、ssh相关类、正则表达式处理类等公共组件 |
| 线程（Thread）模块            | 静(动)态库 | 封装了线程、锁、条件变量等与线程相关的类，以及线程组类、条件变量处理类、服务器线程处理类 |
| 消息传输（Msg）模块           | 静(动)态库 | 采用统一的接口，分别采用ZMQ和libevent，实现了两种消息传输方式，同时提供了两套客户端和服务端消息传输类，并且支持多线程方式 |
| 远程过程调用（RPC）模块       | 静(动)态库 | 提供了一套客户端和服务端的远程过程调用类，自带ZMQ和libevent两种消息传输方式，也可以自定义，同时采用protobuf实现消息的序列号和反序列号 |
| 事件处理（Event）模块         | 静(动)态库 | 提供了事件处理相关的类，包括事件基础类、事件池、线程安全的生产者-消费者队列、定时器事件服务处理类 |
| 元数据存储 （K-V）模块        | 静(动)态库 | 采用统一接口，实现K-V存储客户端功能，可以根据需要在zookeeper和etcd主选择一种，也可以自定义其他的（目前只实现了etcd） |
| 命令行界面（CLI）模块         | 静(动)态库 | 用于处理命令行相关的请求，实现了postgres服务端消息处理模型，还包含配置管理模块以及监控管理模块 |
| Center应用程序接口（API）模块 | 静(动)态库 | 提供了Center的客户端操作类，负责和Center进程通信，用于向Center发送请求和接收响应 |
| Agent应用程序接口 （API）模块 | 静(动)态库 | 提供了Agent的客户端操作类，负责和Agent进程通信，用于向Agent发送请求和接收响应 |

之所以在代码开发层面，自顶向下、分而治之的拆解为12个独立的模块进行开发，主要是有以下好处：

1. 层次分明，控制了程序设计的复杂性

2. 实现业务隔离，易于维护、问题定位和功能扩充

   对于每个模块而言，对外提供服务时是面向接口的，而模块间调用也只依赖于接口，降低了不同功能间的耦合性，这样在模块内部进行问题修改或功能扩充，对模块间的影响较少。

3. 不仅提高了代码的复用度，还实现真正的功能复用

   以本设计为例，Agent和Center是两个独立的进程，但是他们之间都依赖一些公共的模块，比如日志打印、多线程处理、进程间通信、事件处理等；然而又有些功能是Center独有的，比如元数据存储（K-V）和命令行界面（CLI）；这样只需依据进程的功能，包含所需模块即可，提高代码复用、降低冗余。

4. 有利于团队开发，提高了程序的易读性

   在开发过程中，可以让每个开发小团队，负责一个或若干个模块，进行并行开发，提升开发效率；同时也便于后续的人员上手，可以从模块为单位进行学习。

这12个模块间的依赖关系，如下图所示：

![1543730110676](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543730110676.png)

<center>图4、FDDS内部模块依赖图<center\>  

从上图可以看出，模块间的依赖都是单项依赖，这样就避免了循环依赖，而且依赖关系都是从左向右的，故最右边的日志打印模块（fdd_log）是最基本的模块，其他模块都依赖于它；Center进程（fdd_center）和Agent进程（fdd_agent）在最左边，为最终的可执行二进制进程。

### 1.4、代码目录设计

本节主要描述FDD集群管理系统所有相关代码、配置文件、第三方库和工程文件的存放方式；整个系统的第一级根目录存放内容如下所示：

![1543735242261](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543735242261.png)

<center>图4、FDDS系统根目录存放内容图<center\>  

其中，base目录下存放了组成CM系统的12个模块中，除了Center和Agent进程以及各自对应Api之外的所以基础模块代码，其中的内容如下所示：

![1543735362159](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543735362159.png)

<center>图5、base目录存放内容图<center\> 

Center和Agent进程以及对应api的实现代码和接口文件，分别存放在fdd_center和fdd_agent文件夹中，其中的内容如下图所示：

![1543736840493](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543736840493.png)

<center>图6、fdd_center和fdd_agent文件夹中存放内容图<center\> 

因为本设计实现了ZMQ和libevent两种消息传输方式，同时采用protobuf实现消息的序列号和反序列号，采用ssh协议来实现跨主机通信，故需要这些第三方库的头文件和对应的库；为了兼容Linux和Windows两种运行环境，所以这些第三方库也需要兼容这两种环境，这些文件都存放在Third-party目录中，该目录内的内容如下所示：

![1543738665108](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543738665108.png)

<center>图7、Third-party目录中存放的内容图<center\> 

其中Linux和Windows文件夹里面存放的是两种运行环境下相对应的第三方库文件和lib，以及VS2017的工程文件，里面存放的内容如下图所示：

![1543740880516](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543740880516.png)

<center>图8、第三方库目录中存放的内容图<center\> 

 注1：本设计之所以兼容Windows，只是为了借助Windows上便捷的开发和调试方式，以便大大缩短前中期开发周期、代码调试周期和提前发现各种代码静态问题，而其中有些实现是采用打桩或者简单的模拟方式实现，所以Windows上的功能可能会有所欠缺。

接下来的章节，将分别叙述组成CM系统12个模块的详细设计过程：

## 二、Center进程模块设计

Center进程，是整个CM系统的”大脑“，负责指挥着整个系统的运行，提供与客户交互的界面，用于根据客户请求生成对应的执行计划；Center进程和其他模块间的关系如下图所示：

![1543742594612](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543742594612.png)

<center>图9、Center进程和其他模块的依赖图<center\> 

从上图可以看出，Center进程依赖于除Agent进程之外的所有模块，之所以Center进程需要依赖这么多模块，主要是由Center所需要实现的功能决定的：

1. 需要接受客户端psql请求，做出相应的响应
2. 需要处理进程间通信
3. 需要和K-V存储进行数据交互
4. 需要进行Center进程间选主功能
5. 需要执行定时器任务，监控集群节点状态，指定相应决策
6. 需要定时进行资源回收

为了保证上面列举的几项功能互补影响，所以需要采用并发处理策略，在多进程和多线程两种方案中，综合考虑到模块间的资源共享问题以及center的功能特点，最终本设计采用多线程的方案，具体的线程组规划如下图所示：

![1543744745101](E:\代码\git\flying_dev\doc\FDD集群管理开发详细设计image\1543744745101.png)

<center>图10、Center的多线程规划图<center\> 







